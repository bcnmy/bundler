name: "relayer-server"
namespace: "sdk-prod"
index: 0


relayer:
  environment: "production"
  name: "relayer-server"
  image: "gcr.io/biconomy-prod/sdk/relayer-node-service:latest"
  port: "3000"
  replicaCount: 1 
  resource:
    requests:
      memory: "6000Mi"
      cpu: "2000m"
    limits:
      memory: "6000Mi"
      # cpu: "4000m" # don't need to set limit Ref: https://home.robusta.dev/blog/stop-using-cpu-limits

secret_encrypted:
  projectID: biconomy-prod
  key: sdk-prod-relayer-node-service
  config:
    name: config.json.enc

secret_plain:
  projectID: biconomy-prod
  key: sdk-prod-relayer-node-service-plain
  config:
    name: production.json

  
ingress:
  host: sdk-relayer.prod.biconomy.io

# deploy to dedicated k8s node with taint
affinity_tolerations:
  enable: true 
  key: "app"
  values: "relayer-server"

# make sure pods are deployed in different nodes
affinity: 
  antiAffinity:
    topologyKey: "kubernetes.io/hostname"
    weight: 100
    
# wait for 120 * 10s to fail
startupProbe:
  failureThreshold: 120

datadog:
  enable: true
  env: "production"

  service: "sdk-relayer-service"
  version: "v3.15.0"
  lib_version: "v3.16.0"

  configs:
    DD_TRACE_DEBUG: "false"
    DD_TRACE_STARTUP_LOGS: "false"
    DD_PROFILING_ENABLED: "true"
    DD_LOGS_INJECTION: "false"
    DD_RUNTIME_METRICS_ENABLED: "true"
